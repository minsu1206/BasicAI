{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1NdkNHB9Q0v5hLXSbr4+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minsu1206/BasicAI/blob/main/MNIST_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4qV0pG2P3N",
        "outputId": "b3d5c960-457e-4330-ada4-e93749cfa4fe"
      },
      "source": [
        "% tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAmp8IUU2SX8"
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "mnist = fetch_openml('mnist_784')\n",
        "N = 40000\n",
        "indices = np.random.permutation(range(70000))[:N]\n",
        "X = mnist.data[indices]\n",
        "y = mnist.target[indices]\n",
        "Y = np.eye(10)[y.astype(int)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8)\n",
        "X_train , X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=4000)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k5dQWDPvVDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bc6736-bd0a-47a9-dcad-76d1e491e39c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dropout\n",
        "from sklearn.utils import shuffle\n",
        "from keras import backend as K # 별칭으로 따로 구분되어있지 않은 함수는 keras.backend로 처리 수행\n",
        "import keras\n",
        "\n",
        "def W(shape):\n",
        "    return K.truncated_normal(shape, stddev=0.01)\n",
        "\n",
        "n_in = 784\n",
        "n_hiddens=[200,200,200]\n",
        "n_out = 10\n",
        "p_keep=0.5\n",
        "activation = 'relu'\n",
        "layer = [n_in]+n_hiddens\n",
        "init = tf.keras.initializers.TruncatedNormal(mean=0, stddev=0.05, seed=None)\n",
        "# weight의 초기화가 꼭 필요함. keras의 경우ㅇㅇ\n",
        "model = Sequential()\n",
        "for i, input_dim in enumerate((layer)[:-1]):\n",
        "    model.add(Dense(n_hiddens[i], input_dim=input_dim,\n",
        "                   kernel_initializer=init))\n",
        "    model.add(Activation(activation))\n",
        "    model.add(Dropout(p_keep))\n",
        "model.add(Dense(n_out, kernel_initializer=init))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xyx4c5F2Z1d",
        "outputId": "a4292647-f8ad-44da-fc60-e0194cc9efde"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01),metrics=['accuracy'])\n",
        "epochs = 50\n",
        "batch_size = 200\n",
        "hist = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                 validation_data=(X_validation, y_validation))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 28000 samples, validate on 4000 samples\n",
            "Epoch 1/50\n",
            "28000/28000 [==============================] - 2s 66us/step - loss: 2.8147 - accuracy: 0.3303 - val_loss: 1.1314 - val_accuracy: 0.6805\n",
            "Epoch 2/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 1.2855 - accuracy: 0.5874 - val_loss: 0.7507 - val_accuracy: 0.7928\n",
            "Epoch 3/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 1.0373 - accuracy: 0.6751 - val_loss: 0.6166 - val_accuracy: 0.8465\n",
            "Epoch 4/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.9292 - accuracy: 0.7085 - val_loss: 0.5511 - val_accuracy: 0.8637\n",
            "Epoch 5/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.8488 - accuracy: 0.7344 - val_loss: 0.4860 - val_accuracy: 0.8835\n",
            "Epoch 6/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.7993 - accuracy: 0.7552 - val_loss: 0.4765 - val_accuracy: 0.8890\n",
            "Epoch 7/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.7582 - accuracy: 0.7668 - val_loss: 0.4447 - val_accuracy: 0.8945\n",
            "Epoch 8/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.7148 - accuracy: 0.7851 - val_loss: 0.4327 - val_accuracy: 0.8975\n",
            "Epoch 9/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.6810 - accuracy: 0.7979 - val_loss: 0.3938 - val_accuracy: 0.9057\n",
            "Epoch 10/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.6559 - accuracy: 0.8091 - val_loss: 0.3885 - val_accuracy: 0.9043\n",
            "Epoch 11/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.6243 - accuracy: 0.8179 - val_loss: 0.3620 - val_accuracy: 0.9153\n",
            "Epoch 12/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.5938 - accuracy: 0.8269 - val_loss: 0.3523 - val_accuracy: 0.9147\n",
            "Epoch 13/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.5837 - accuracy: 0.8358 - val_loss: 0.3514 - val_accuracy: 0.9145\n",
            "Epoch 14/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.5587 - accuracy: 0.8421 - val_loss: 0.3263 - val_accuracy: 0.9168\n",
            "Epoch 15/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.5414 - accuracy: 0.8455 - val_loss: 0.3257 - val_accuracy: 0.9227\n",
            "Epoch 16/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.5282 - accuracy: 0.8537 - val_loss: 0.3384 - val_accuracy: 0.9245\n",
            "Epoch 17/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.5176 - accuracy: 0.8562 - val_loss: 0.3204 - val_accuracy: 0.9200\n",
            "Epoch 18/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.5042 - accuracy: 0.8570 - val_loss: 0.3170 - val_accuracy: 0.9240\n",
            "Epoch 19/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.4962 - accuracy: 0.8646 - val_loss: 0.3153 - val_accuracy: 0.9270\n",
            "Epoch 20/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.4845 - accuracy: 0.8646 - val_loss: 0.2978 - val_accuracy: 0.9290\n",
            "Epoch 21/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.4834 - accuracy: 0.8654 - val_loss: 0.2964 - val_accuracy: 0.9265\n",
            "Epoch 22/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.4620 - accuracy: 0.8729 - val_loss: 0.2969 - val_accuracy: 0.9270\n",
            "Epoch 23/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.4605 - accuracy: 0.8723 - val_loss: 0.2885 - val_accuracy: 0.9273\n",
            "Epoch 24/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.4464 - accuracy: 0.8781 - val_loss: 0.2776 - val_accuracy: 0.9298\n",
            "Epoch 25/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.4434 - accuracy: 0.8787 - val_loss: 0.2825 - val_accuracy: 0.9308\n",
            "Epoch 26/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.4365 - accuracy: 0.8802 - val_loss: 0.2679 - val_accuracy: 0.9327\n",
            "Epoch 27/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.4351 - accuracy: 0.8809 - val_loss: 0.2747 - val_accuracy: 0.9358\n",
            "Epoch 28/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.4139 - accuracy: 0.8856 - val_loss: 0.2622 - val_accuracy: 0.9327\n",
            "Epoch 29/50\n",
            "28000/28000 [==============================] - 2s 54us/step - loss: 0.4168 - accuracy: 0.8864 - val_loss: 0.2709 - val_accuracy: 0.9335\n",
            "Epoch 30/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.4019 - accuracy: 0.8911 - val_loss: 0.2558 - val_accuracy: 0.9345\n",
            "Epoch 31/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.4062 - accuracy: 0.8917 - val_loss: 0.2568 - val_accuracy: 0.9337\n",
            "Epoch 32/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.4002 - accuracy: 0.8910 - val_loss: 0.2589 - val_accuracy: 0.9333\n",
            "Epoch 33/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3869 - accuracy: 0.8970 - val_loss: 0.2526 - val_accuracy: 0.9337\n",
            "Epoch 34/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3857 - accuracy: 0.8954 - val_loss: 0.2556 - val_accuracy: 0.9352\n",
            "Epoch 35/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3755 - accuracy: 0.8971 - val_loss: 0.2546 - val_accuracy: 0.9367\n",
            "Epoch 36/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3715 - accuracy: 0.8997 - val_loss: 0.2430 - val_accuracy: 0.9348\n",
            "Epoch 37/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3752 - accuracy: 0.9000 - val_loss: 0.2466 - val_accuracy: 0.9358\n",
            "Epoch 38/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3646 - accuracy: 0.9008 - val_loss: 0.2427 - val_accuracy: 0.9365\n",
            "Epoch 39/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3563 - accuracy: 0.9040 - val_loss: 0.2440 - val_accuracy: 0.9390\n",
            "Epoch 40/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.3620 - accuracy: 0.9042 - val_loss: 0.2451 - val_accuracy: 0.9390\n",
            "Epoch 41/50\n",
            "28000/28000 [==============================] - 2s 55us/step - loss: 0.3490 - accuracy: 0.9082 - val_loss: 0.2442 - val_accuracy: 0.9388\n",
            "Epoch 42/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3567 - accuracy: 0.9035 - val_loss: 0.2377 - val_accuracy: 0.9385\n",
            "Epoch 43/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3471 - accuracy: 0.9077 - val_loss: 0.2362 - val_accuracy: 0.9408\n",
            "Epoch 44/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3465 - accuracy: 0.9068 - val_loss: 0.2352 - val_accuracy: 0.9408\n",
            "Epoch 45/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3392 - accuracy: 0.9096 - val_loss: 0.2420 - val_accuracy: 0.9408\n",
            "Epoch 46/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3369 - accuracy: 0.9089 - val_loss: 0.2357 - val_accuracy: 0.9405\n",
            "Epoch 47/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3322 - accuracy: 0.9081 - val_loss: 0.2276 - val_accuracy: 0.9415\n",
            "Epoch 48/50\n",
            "28000/28000 [==============================] - 2s 56us/step - loss: 0.3349 - accuracy: 0.9099 - val_loss: 0.2236 - val_accuracy: 0.9410\n",
            "Epoch 49/50\n",
            "28000/28000 [==============================] - 2s 57us/step - loss: 0.3273 - accuracy: 0.9116 - val_loss: 0.2245 - val_accuracy: 0.9430\n",
            "Epoch 50/50\n",
            "28000/28000 [==============================] - 2s 58us/step - loss: 0.3259 - accuracy: 0.9124 - val_loss: 0.2198 - val_accuracy: 0.9417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "HlUeOa0h2gSZ",
        "outputId": "1c0cf067-42ed-42e0-e6e6-0a964046dd13"
      },
      "source": [
        "val_acc = hist.history['accuracy']\n",
        "# https://stackoverflow.com/questions/54602399/why-am-i-having-keyerror-val-acc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='serif')\n",
        "fig = plt.figure()\n",
        "plt.plot(range(epochs), val_acc, label='acc', color='black')\n",
        "plt.xlabel('epochs')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrCO0rQO2iox",
        "outputId": "241b6e9a-0f83-44de-9fa1-d34d6b1d7a0c"
      },
      "source": [
        "loss_and_metrics = model.evaluate(X_test, y_test)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000/8000 [==============================] - 0s 38us/step\n",
            "[0.22544353833049535, 0.9415000081062317]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw4wKXOY2kjh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
